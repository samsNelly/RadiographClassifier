# Lung Radiograph Classifier
This repository contains a Jupyter notebook with three different machine learning models to predict diagnoses based on lung radiograph data.

## Logistic Regression (Binary Classifier)
	I built a binary classifier to predict whether a lung radiograph is healthy or unhealthy using logistic regression, which achieved an accuracy of 76.0% on the training set and 75.1% on the testing set, indicating good generalization and minimal overfitting. I oversampled the healthy lung class, so it accounted for roughly 50% of the data, improving the balance across classes. To reduce overfitting, I simplified the feature space by resizing images from 128x128 to 64x64 pixels, lowering the dimensionality from 16,384 to 4,096 raw pixel features. This made the input more manageable for logistic regression, which performs best on low-dimensional, informative inputs with minimal noise.

    The model had an Area Under the ROC Curve (AUC) of 0.825 which is near a perfect AUC of 1 (perfect distinction between classes), indicating that it was successful in ranking unhealthy lungs radiographs above healthy ones. Precision was 77.1% for unhealthy lungs and 73.2% for healthy lungs, indicating solid confidence in both predictions. Recall was 73.5% for unhealthy lungs and 76.8% for healthy lungs, meaning the model correctly detected 73.5% of all actual unhealthy cases and 76.8% of all actual healthy cases. F1-scores of 75.3% (unhealthy) and 75.0% (healthy) reflect strong overall performance across both precision and recall.

    While the model demonstrates reasonable performance for the distinction between healthy and unhealthy lungs overall, its effectiveness varies significantly when distinguishing between each of the unhealthy categories. COVID-19 cases were correctly classified 33.3% of the time, while Pneumonia and Other cases had much lower accuracies of 9.7% and 25.9%, respectively. The results suggest that the model struggles to detect certain conditions, which is likely caused by limitations of using a linear classifier or subtle visual differences between lung radiograph images.

## K-Nearest Neighbors (Binary Classifier)
    I implemented a K-Nearest Neighbors (KNN) classifier as an alternative to logistic regression. Since KNN is sensitive to feature scale, I standardized the input features using StandardScaler from SKLearn, ensuring all pixel intensities provided equal contribution to distance calculation. I used a value of 7 for the number of neighbors because it minimizes the chance of ties and improves prediction accuracy by considering a broader local neighborhood.

	To maintain consistency with calculated metrics for the model, I used the same data preprocessing techniques as in the logistic regression model. This included downsizing the images to 64x64 pixels, reducing dimensionality and noise, and I balanced the dataset to ensure the healthy lungs class made up about ~50% of the training data.
	The KNN classifier achieved an accuracy of 83% and an AUC score of 0.90, with F1-scores for healthy and unhealthy lungs of 0.84 and 0.83, respectively. While both models performed reasonably well, KNN outperformed logistic regression across all metrics, making more accurate distinctions between healthy versus unhealthy lungs in this feature space. Though KNN had an increase in performance, it may be slower when using larger datasets due to the requirements of storing and searching through the training data for each prediction.

## 4-Layer Neural Network (Multi-Class Classifier)
    To classify lung radiograph images into four distinct categories– Normal, COVID-19, Pneumonia, and Non-COVID Infection– I developed a multi-layer neural network using PyTorch. This model expands on the binary classification implementation to now handle a 4-class classification problem. 

    I implemented a 4-layer fully connected neural network with the input layer that accepts 64x64 images, flattened into a vector of size 4096. The first hidden layer is reduced to 1024 neurons, the second layer is reduced to 256 neurons, the third layer is reduced to 64 neurons, and the output layer contains 4 neurons, one for each class. I applied a dropout to the first layer, which randomly disables 30% of neurons, encouraging the network model to learn redundant representations of the image data to improve generalization and reduce the likelihood of overfitting the model to the training dataset.

    To address the natural imbalance in datasets and avoid bias toward dominant classes like Normal and COVID-19, I created a data balancer which ensures that each class has an equal number of training samples. Underrepresented classes are oversampled by using image augmentations for random samples of the original image data, applying mild brightness adjustment and Gaussian blur. Overrepresented classes are undersampled by randomly selecting a subset of the data. For this model, I chose to take 6000 samples from each class of lungs.

    I utilized Cross Entropy Loss as my loss function for training the model. During training, I created a confusion matrix and noticed that Pneumonia was being predicted the best (~90%) whereas the other classes fell between ~65-75% accuracy, so I added weights to my loss function to penalize the misclassification of Normal, COVID-19, and Non-COVID Infections. I tried using both Adam and SGD as my optimizer, but I ultimately chose Adam because it provided smoother, quicker convergence. I adjusted the number of epochs based on convergence and overfitting behavior, but I selected 70 epochs because the model showed steady improvements in training and testing loss until around epoch 60, after which training loss started to dip below testing loss, indicating potential overfitting. I chose a batch size of 256 because it served as a good medium between efficient training and promotion of gradient stability, allowing the model to generalize better and reduce my original computation time when using a batch size of 512.

    The model achieved an accuracy of 85.7% on the testing set, with the highest F1-score Pneumonia (97.4%), indicating strong performance in detecting Pneumonia cases. The other classes– Normal, COVID-19, and Non-COVID Infections– also performed well, with F1-scores around 80-83%. While there is room for improvement in distinguishing visually similar lung radiographs, the model demonstrates solid generalization and serves as an effective baseline for multi-class lung radiograph classification.

